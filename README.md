# Cardinality Constrained Portfolio Optimisation

## Context

This project was originally a part of a group coursework during my Masterâ€™s degree, in which I was tasked with implementing the logic of the algorithms into code. Since this was a lengthy process, the analysis was completed mainly by other team members. Being interested in this matter, I have therefore decided to start developing the project further with the aim of completing the analysis part myself.

## Introduction

In this project we aimed to use  and then compare the performance of Random Search and Genetic algorithms to optimise cardinality constrained portfolios. Given relatively extensive nature of the implementation and subsequent analysis the project is broken down into 4 parts:

- Implementation of Random Search algorithm (Random Search.py)
- Implementation of Genetic algorithm (Genetic Algorithm.py)
- Implementation of Genetic algorithm using different Population Sizes (Genetic Algorithm Population Size.py)
- Analysis of the results (Analysis.ipynb)

### Data
The data was given to us as part of the coursework in 5 .txt files. These 5 files represent 5 capital market trading indices from around the world:
- `assets1.txt` - Hang Seng (Hong Kong)
- `assets2.txt` - DAX 100 (Germany)
- `assets3.txt` - FTSE 100(UK)
- `assets4.txt` - S&P 100 (USA)
- `assets5.txt` - Nikkei 225 (Japan)

## Each dataset is structured in the following fashion:
![Screenshot 2021-06-15 at 22 19 48](https://user-images.githubusercontent.com/85829899/122634002-e565c780-d0db-11eb-949a-bfc2c4c8989b.png)

## Main Objective

The main goal of the implementation was to minimize the following function 50 times, using 50 equally spaced values of ğœ† (from 0 to 1):

                                      ğ‘“(ğ‘ ) = ğœ† Â· ğ¶ğ‘œğ‘‰ğ‘ğ‘Ÿ(ğ‘ ) âˆ’ (1 âˆ’ ğœ†) Â· ğ‘…(ğ‘ )  

Where: 						
                                
                                                ğ¶ğ‘œğ‘‰ğ‘ğ‘Ÿ = âˆ‘âˆ‘ğ‘¤ğ‘–ğ‘¤ğ‘—ğœŒğ‘–ğ‘—ğœğ‘–ğœğ‘— 	

                                                     ğ‘… = âˆ‘ğ‘¤ğ‘–ğœ‡ğ‘–
          
- s - a candidate solution (in this case a portfolio)
- ğ¶ğ‘œğ‘‰ğ‘ğ‘Ÿ(ğ‘ ) - Covariance of a portfolio
- ğ‘…(ğ‘ ) - Expected return of a portfolio
- ğœ† - expresses the tradeoff between risk/return 
- ğ‘¤ğ‘– - proportion of total investment invested in asset i
- ğœ‡ğ‘–  - expected return of asset i
- ğ‘¤ğ‘— - proportion of total investment invested in asset j
- ğœŒğ‘–j - correlation between assets i and j 
- ğœğ‘– - standard deviation of return of asset i
- ğœğ‘— - standard deviation of return of asset j

## Algorithm Implementation

The logic of the algorithms used are depicted below. The actual heuristics will not be discussed in detail, however they are explained in great detail in T.-J. Chang, et. al (2000) paper, which was followed for transforming the algorithms into code. The paper can also be found in the repository. 

## Random Search Algorithm

![Screenshot 2021-06-15 at 21 58 05](https://user-images.githubusercontent.com/85829899/122634011-f7476a80-d0db-11eb-8a90-8397a1a59642.png)

## Genetic Algorithm

![Screenshot 2021-06-15 at 21 05 19](https://user-images.githubusercontent.com/85829899/122634018-ff070f00-d0db-11eb-83c1-39d504d6baa2.png)
 
## Reproducing the Project
To reproduce the whole project, you frist need to  download the Datasets folder, Random Search.py, Genetic Algorithm.py and Genetic Algorithm Population Size.py. The python scripts then need to be run one by one. As mentioned in the limitations part of the analysis the run times are quite substantial. The scripts will create  80 .csv files that are used in the Analysis.ipynb. In order for the latter to work, place folders generated by Random Search.py and Genetic Algorithm.py into /Generated data/Different Lambdas and files generated by Genetic Algorithm Population Size.py into /Generated data/Different Populations (Optionally you can channge the file path in the code)

## Reproducing the Analysis
Alternatively, to reproduce just the analysis part, download Analysis.ipynb and Generated data files.

## Credits
Big thanks to: Eileen Neumann, Alexandra Firkowska, Kristina Popelkova, Shriya Raina and Denis Mclaughlin who were part of my coursework team and have worked tirelessly on delivering the initial version of the project.
